# Indice

1. [IntroducciÃ³n](#introducciÃ³n)
2. [Distribuciones](#distribuciones-analizadas)
    - [DistribuciÃ³n Normal](#DistribuciÃ³n-Normal)

# Distribuciones

# DistribuciÃ³n Normal

Este proyecto tiene como objetivo explorar y comparar **tres pruebas estadÃ­sticas de normalidad** utilizando Python, a travÃ©s de un ejemplo prÃ¡ctico con datos simulados. Incluye visualizaciones, interpretaciÃ³n crÃ­tica y consideraciones tÃ©cnicas que demuestran cÃ³mo evaluar la normalidad en un conjunto de datos.

---

## ğŸ“š Contenido del Notebook

El archivo [`distribucion_normal.ipynb`](./distribucion_normal.ipynb) incluye:

### 1. **GeneraciÃ³n de Datos**
- SimulaciÃ³n de una variable sesgada (log-normal) para probar los lÃ­mites de cada test.

### 2. **VisualizaciÃ³n**
- Histograma con curva de densidad.
- AnÃ¡lisis visual previo a los test estadÃ­sticos.

### 3. **AplicaciÃ³n de Tests de Normalidad**
Se aplican las siguientes pruebas:
- ğŸ“ **Shapiro-Wilk**
- ğŸ“ˆ **Kolmogorov-Smirnov** (ajustada a $ \mu$, $\sigma$)
- ğŸ“‰ **Dâ€™Agostino y Pearson** (`normaltest`)

### 4. **ComparaciÃ³n de Resultados**
- AnÃ¡lisis de casos donde **una prueba detecta desviaciones** de la normalidad y otras no.
- DiscusiÃ³n sobre causas y recomendaciones.

---

## ğŸ§  Fundamento MatemÃ¡tico

### ğŸ“Œ FÃ³rmula de la distribuciÃ³n normal:

$$
f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \cdot e^{ -\frac{(x - \mu)^2}{2\sigma^2} }
$$

Donde:
- $\mu$ : media.
- $\sigma$ : desviaciÃ³n estÃ¡ndar.
- $x$ : valor de la variable aleatoria.

---

## ğŸ§ª InterpretaciÃ³n EstadÃ­stica

Cada prueba evalÃºa la hipÃ³tesis:

**Hâ‚€:** los datos siguen una distribuciÃ³n normal.

| Prueba                    | Â¿CuÃ¡ndo usarla?                                   | Ventajas                             |
|--------------------------|----------------------------------------------------|--------------------------------------|
| **Shapiro-Wilk**         | Muestras pequeÃ±as o medianas (n < 5000)            | Alta potencia                        |
| **Kolmogorov-Smirnov**   | ComparaciÃ³n con una dist. teÃ³rica ajustada         | Simple de aplicar, menos sensible    |
| **Dâ€™Agostino y Pearson** | Muestras medianas/grandes con sesgos o curtosis    | EvalÃºa forma de la curva             |

---

## âœ… Resultados Esperados (Ejemplo)

```text
Shapiro-Wilk:            p = 0.1675  âœ…
Kolmogorov-Smirnov:      p = 0.0501  âš ï¸
Dâ€™Agostino-Pearson:      p = 0.0241  âŒ
